---
title: "Data 622 Test1"
author: "Samriti Malhotra"
date: "11/11/2020"
output:
  word_document: default
  html_document: default
  pdf_document: default
---


```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
library(dplyr)
library(kableExtra)
library(ggplot2)
library(ipred)
library(ROCR)
library(e1071)
library(pROC)
library(class)
```

## Read Data
```{r}



df <- read.csv("data_hw1_622.csv", header = TRUE, sep =",") 
str(df)
# printing the top 5 rows of the data frame.
kable(head(df)) %>% 
  kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"),full_width   = F,position = "left",font_size = 12) %>%
  row_spec(0, background ="gray") 

ggplot(df,aes(y=Y,x=X,color=label)) + geom_point()
```
The data has 36 rows and 3 columns , out of which columns 'Y' and 'label' are Character and column 'X' is int, but all the columns are categorical in nature and hence can be converted to factors  to be consistent.                                                                         

### Prepare data                                                           


```{r}
df$X = as.factor(df$X)
df$Y = as.factor(df$Y)
df$label = as.factor(df$label)
#df[sapply(df, is.character)] <- lapply(df[sapply(df, is.character)], as.factor)

# summary statistics of the columns
summary(df)
str(df)
```

## Split Dataset                                             
```{r}

set.seed(53)

trainidx<-sample(1:nrow(df) , size=round(0.77*nrow(df)),replace=F) 
train_set <- df[trainidx,]
test_set <- df[-trainidx,]


```
                                    
##  (A) Run Bagging (ipred package)   

  -- sample with replacement

  -- estimate metrics for a model

  -- repeat as many times as specied and report the average

```{r}
# Bagging
trainBgModel <- bagging(label ~ ., data=train_set, nbagg = 100, coob = TRUE)
trainBgModel

confMat_train <- table(predict(trainBgModel), train_set$label)
confMat_train

testbag = predict(trainBgModel, newdata=test_set)
confusionMat_bg <- table(testbag, test_set$label)
confusionMat_bg


```

```{r}
# Calculating  the ACC,TPR,FPR,TNR & FNR from confusion matrix
acc_bag <- sum(diag(confusionMat_bg)) / sum(confusionMat_bg)
tpr_bag <- confusionMat_bg[1,1]/sum(confusionMat_bg[1,1], confusionMat_bg[2,1])
fpr_bag <- confusionMat_bg[1,2]/sum(confusionMat_bg[1,2], confusionMat_bg[2,2])
tnr_bag <- confusionMat_bg[2,2]/sum(confusionMat_bg[2,2], confusionMat_bg[1,2]) 
fnr_bag <- confusionMat_bg[2,1]/sum(confusionMat_bg[2,1], confusionMat_bg[1,1])
auc_bag <- auc(roc(testbag, ifelse(test_set$label == 'BLUE', 1, 0)))

Bgrow <- c("Bagging ",round(auc_bag,2), round(acc_bag,2),round(tpr_bag,2),round(fpr_bag,2), round(tnr_bag,2),round(fnr_bag,2))

Bgrow

resMatrix <- data.frame(matrix(ncol = 6, nrow = 0))
resMatrix <- rbind(resMatrix,Bgrow)
colnames(resMatrix) <- c("ALGO", "AUC","ACC", "TPR", "FPR", "TNR ", "FNR")

```
                                             
## (B) Run LOOCV (jacknife) for the same dataset 

  

--- iterate over all points

     -- keep one observation as test

    -- train using the rest of the observations

    -- determine test metrics

    -- aggregate the test metrics

end of loop

find the average of the test metric(s)

Compare (A), (B) above with the results you obtained in HW-1  and write 3 sentences explaining the

observed difference.


```{r  message=FALSE, warning=FALSE, paged.print=FALSE}

data <- df
acc <- NULL
for(i in 1:nrow(data))
{
    # Train-test splitting
    # 35 samples -> fitting
    # 1 sample -> testing
    train <- data[-i,]
    test <- data[i,]
    
    
    # Fitting
    model <- glm(label~.,family=binomial,data=train)
    pred_glm <- predict(model,test,type='response')
   
   # If prob > 0.5 then 1, else 0
    results <- ifelse(pred_glm > 0.5,"BLUE","BLACK")
    
    # Actual answers
    answers <- test$label
   
    # Calculate accuracy
    misClasificError <- mean(answers != results)
    
    # Collecting results
    acc[i] <- 1-misClasificError
    
    
}

# Average accuracy of the model

mean(acc)


```
                                        

### Naive Bayes                                   

```{r message=FALSE, warning=FALSE, paged.print=FALSE}

data <- df
acc <- NULL
for(i in 1:nrow(data))
{
    # Train-test splitting
    # 35 samples -> fitting
    # 1 sample -> testing
    train <- data[-i,]
    test <- data[i,]
    
    
    # Fitting
    model <- naiveBayes(label~.,data=train)
    pred_nb <- predict(model,test,type='raw')
   
   # If prob > 0.5 then 1, else 0
    results <- ifelse(pred_nb > 0.5,"BLUE","BLACK")
    
    # Actual answers
    answers <- test$label
   
    # Calculate accuracy
    misClasificError <- mean(answers != results)
    
    # Collecting results
    acc[i] <- 1-misClasificError
}

mean(acc)
```
## Conclusion:

 The accuracy of Bagging method is (.88) and LOOCV produced accuracy of (.51) for NB and (.77) for GLB. Both models performed differently and score better. Bagging is a method to reduce over fitting. It trains many models on resampled data and then take their average to get an averaged model. 
 
 
